{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2e9fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "import re\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from typing import List, Dict, Any, Optional, Tuple \n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a43b447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Konfigurasi Awal ---\n",
    "# Mendefinisikan jalur file input dan output untuk menjaga semua path di satu tempat.\n",
    "RETRIEVAL_FILE = Path(\"data/results/retrieved_cases.json\")\n",
    "CASE_FILE = Path(\"data/processed/cases.json\")\n",
    "OUTPUT_FILE = Path(\"data/results/predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e81c1e6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Mengatur logging untuk memberikan informasi, peringatan, dan kesalahan selama eksekusi.\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ed3c83",
   "metadata": {},
   "source": [
    "--- Fungsi Utilitas ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ffc18e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def initialize_directories(file_path: Path) -> bool:\n",
    "    \"\"\"\n",
    "    Memastikan direktori (folder) tempat file output akan disimpan sudah ada.\n",
    "    Jika belum ada, fungsi ini akan membuatnya.\n",
    "    \n",
    "    Args:\n",
    "        file_path (Path): Objek Path dari file yang akan disimpan.\n",
    "                          Digunakan untuk mendapatkan direktori induknya.\n",
    "        \n",
    "    Returns:\n",
    "        bool: True jika direktori berhasil dipastikan/dibuat, False jika terjadi error.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # parent.mkdir(parents=True, exist_ok=True) akan membuat semua direktori induk yang diperlukan\n",
    "        # dan tidak akan menimbulkan error jika direktori sudah ada.\n",
    "        file_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        logger.info(f\"Output directory '{file_path.parent}' ensured.\")\n",
    "        return True\n",
    "    except OSError as e:\n",
    "        logger.error(f\"Error creating directory {file_path.parent}: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4346d2c2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_json_data(file_path: Path) -> Optional[List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Memuat data dari file JSON yang diberikan.\n",
    "    Fungsi ini juga melakukan validasi dasar untuk memastikan file ada, \n",
    "    formatnya adalah JSON, dan isinya berupa daftar.\n",
    "    \n",
    "    Args:\n",
    "        file_path (Path): Path ke file JSON yang akan dimuat.\n",
    "        \n",
    "    Returns:\n",
    "        Optional[List[Dict[str, Any]]]: Daftar kamus (data JSON) jika berhasil dimuat.\n",
    "                                         Mengembalikan None jika ada kesalahan (file tidak ditemukan,\n",
    "                                         format JSON salah, dll.).\n",
    "                                         Mengembalikan daftar kosong jika file ada tapi isinya kosong.\n",
    "    \"\"\"\n",
    "    if not file_path.exists():\n",
    "        logger.error(f\"File '{file_path}' not found.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "        # Memastikan data yang dimuat adalah sebuah list (daftar)\n",
    "        if not isinstance(data, list):\n",
    "            logger.error(f\"Invalid data format in '{file_path}'. Expected a JSON array, got {type(data).__name__}.\")\n",
    "            return None\n",
    "            \n",
    "        # Memperingatkan jika file JSON kosong\n",
    "        if not data:\n",
    "            logger.warning(f\"No data found in '{file_path}'.\")\n",
    "            return []\n",
    "            \n",
    "        logger.info(f\"Successfully loaded {len(data)} entries from '{file_path}'.\")\n",
    "        return data\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        logger.error(f\"Failed to parse JSON from '{file_path}'. Invalid JSON format: {e}\")\n",
    "        return None\n",
    "    except UnicodeDecodeError as e:\n",
    "        logger.error(f\"Encoding error reading '{file_path}': {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error reading '{file_path}': {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbc6478",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def extract_pasals(text: Optional[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Mengekstrak semua referensi pasal dari sebuah string teks menggunakan ekspresi reguler.\n",
    "    Fungsi ini juga akan membersihkan dan menghilangkan duplikasi pasal yang ditemukan.\n",
    "    Contoh: \"Pasal 10, Pasal 10 Ayat (1) huruf a\" akan menjadi [\"Pasal 10\", \"Pasal 10 Ayat (1) Huruf A\"].\n",
    "    \n",
    "    Args:\n",
    "        text (Optional[str]): String teks yang mungkin berisi pasal-pasal.\n",
    "                              Bisa berupa None jika tidak ada teks.\n",
    "        \n",
    "    Returns:\n",
    "        List[str]: Daftar string pasal yang sudah diekstrak, dibersihkan, dan unik.\n",
    "    \"\"\"\n",
    "    # Ekspresi reguler untuk mencocokkan pola \"Pasal X Ayat (Y) huruf Z\"\n",
    "    # re.IGNORECASE memastikan pencocokan tidak sensitif huruf besar/kecil.\n",
    "    pasal_pattern = re.compile(\n",
    "        r\"Pasal\\s+\\d+(?:\\s+Ayat\\s+\\(\\d+\\))?(?:\\s+huruf\\s+[a-zA-Z])?\",\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "    \n",
    "    # Mencari semua pola pasal dalam teks (jika teks bukan None)\n",
    "    pasals = pasal_pattern.findall(text or \"\")\n",
    "    \n",
    "    # Membersihkan setiap pasal:\n",
    "    # 1. Mengubah ke format Judul (huruf pertama setiap kata kapital).\n",
    "    # 2. Menghilangkan spasi ekstra di awal/akhir.\n",
    "    # 3. Memastikan pasal tidak kosong setelah dibersihkan.\n",
    "    pasals = [p.title().strip() for p in pasals if p.strip()] \n",
    "    \n",
    "    # Menghilangkan duplikasi sambil menjaga urutan asli yang ditemukan.\n",
    "    # list(dict.fromkeys(pasals)) adalah cara yang Pythonic untuk melakukan ini.\n",
    "    return list(dict.fromkeys(pasals))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75977ab",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def majority_vote(cases: List[Dict[str, Any]]) -> str:\n",
    "    \"\"\"\n",
    "    Melakukan 'majority vote' untuk menentukan solusi yang diprediksi \n",
    "    berdasarkan pasal-pasal yang paling sering muncul di antara kasus-kasus yang relevan.\n",
    "    \n",
    "    Args:\n",
    "        cases (List[Dict[str, Any]]): Daftar kamus kasus yang relevan (misalnya, top-k kasus yang diambil).\n",
    "        \n",
    "    Returns:\n",
    "        str: String yang berisi 5 pasal paling sering muncul (atau kurang jika tidak ada 5),\n",
    "             dipisahkan dengan \"; \". Mengembalikan \"N/A\" jika tidak ada pasal yang dapat ditemukan.\n",
    "    \"\"\"\n",
    "    pasal_counter = Counter() # Counter adalah alat yang efisien untuk menghitung frekuensi item.\n",
    "    \n",
    "    for case in cases:\n",
    "        # Memastikan setiap item yang diproses adalah kamus\n",
    "        if not isinstance(case, dict):\n",
    "            logger.warning(f\"Skipping non-dictionary case in majority vote: {case}\")\n",
    "            continue\n",
    "        \n",
    "        # Mengekstrak pasal dari bidang 'pasal' setiap kasus\n",
    "        pasals = extract_pasals(case.get(\"pasal\", \"\"))\n",
    "        \n",
    "        # Menambahkan pasal yang ditemukan ke counter\n",
    "        pasal_counter.update(pasals)\n",
    "    \n",
    "    # Jika tidak ada pasal yang ditemukan sama sekali dari semua kasus\n",
    "    if not pasal_counter:\n",
    "        return \"N/A\" \n",
    "        \n",
    "    # Mengambil 5 pasal yang paling sering muncul (top common)\n",
    "    # Jika kurang dari 5, itu akan mengembalikan semua yang ditemukan.\n",
    "    top_pasals = [pasal for pasal, _ in pasal_counter.most_common(5)]\n",
    "    \n",
    "    # Menggabungkan pasal-pasal teratas menjadi satu string\n",
    "    return \"; \".join(top_pasals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5db6f5b",
   "metadata": {},
   "source": [
    "--- Fungsi Utama ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93334557",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Fungsi utama yang mengatur alur kerja prediksi.\n",
    "    Ini akan:\n",
    "    1. Memastikan direktori output ada.\n",
    "    2. Memuat data hasil retrieval dan data kasus dasar.\n",
    "    3. Memproses setiap kueri, menemukan kasus-kasus yang relevan.\n",
    "    4. Melakukan majority vote pada pasal-pasal kasus relevan untuk memprediksi solusi.\n",
    "    5. Menyimpan hasil prediksi ke file CSV.\n",
    "    \"\"\"\n",
    "    # Langkah 1: Pastikan direktori output untuk file CSV ada.\n",
    "    if not initialize_directories(OUTPUT_FILE):\n",
    "        return # Keluar jika direktori tidak dapat dibuat\n",
    "\n",
    "    logger.info(\"Starting prediction process...\")\n",
    "\n",
    "    # Langkah 2: Muat data hasil retrieval (kasus-kasus yang paling mirip dengan kueri).\n",
    "    retrieved_data = load_json_data(RETRIEVAL_FILE)\n",
    "    if retrieved_data is None:\n",
    "        logger.error(\"Failed to load retrieval data. Exiting.\")\n",
    "        return\n",
    "    if not retrieved_data:\n",
    "        logger.warning(\"No retrieval data found. Nothing to predict.\")\n",
    "        return\n",
    "\n",
    "    # Langkah 3: Muat data kasus dasar (semua kasus yang diketahui).\n",
    "    case_data = load_json_data(CASE_FILE)\n",
    "    if case_data is None:\n",
    "        logger.error(\"Failed to load case base data. Exiting.\")\n",
    "        return\n",
    "    if not case_data:\n",
    "        logger.warning(\"No case base data found. Cannot perform majority voting.\")\n",
    "        return\n",
    "\n",
    "    # Langkah 4: Buat kamus untuk pencarian kasus yang efisien berdasarkan case_id.\n",
    "    # Ini memungkinkan kita dengan cepat mengambil detail kasus hanya dengan ID-nya.\n",
    "    case_dict = {c.get(\"case_id\"): c for c in case_data if c.get(\"case_id\")}\n",
    "    if not case_dict:\n",
    "        logger.error(\"No valid case_ids found in case base. Cannot map retrieved cases.\")\n",
    "        return\n",
    "\n",
    "    results = [] # Daftar untuk menyimpan hasil prediksi akhir\n",
    "    processed_queries = 0 # Penghitung kueri yang berhasil diproses\n",
    "\n",
    "    # Langkah 5: Iterasi (ulang) melalui setiap entri kueri dari data retrieval.\n",
    "    for query_entry in retrieved_data:\n",
    "        # Validasi bahwa entri kueri adalah kamus yang valid.\n",
    "        if not isinstance(query_entry, dict):\n",
    "            logger.warning(f\"Skipping non-dictionary entry in retrieval data: {query_entry}\")\n",
    "            continue\n",
    "\n",
    "        query_id = query_entry.get(\"query_id\", \"UNKNOWN_QUERY\")\n",
    "        # Mengambil daftar ID kasus teratas yang diambil untuk kueri ini.\n",
    "        # Penting: Menggunakan kunci \"top_k_case_ids\" sesuai output skrip retrieval.\n",
    "        top_case_ids = query_entry.get(\"top_k_case_ids\", []) \n",
    "\n",
    "        # Validasi bahwa top_case_ids adalah daftar.\n",
    "        if not isinstance(top_case_ids, list):\n",
    "            logger.warning(f\"Skipping query {query_id}: 'top_k_case_ids' is not a list. Type: {type(top_case_ids).__name__}\")\n",
    "            continue\n",
    "            \n",
    "        top_cases = [] # Daftar untuk menyimpan objek kasus lengkap dari top_case_ids\n",
    "        # Mengambil objek kasus lengkap dari case_dict menggunakan ID yang diambil\n",
    "        for cid in top_case_ids:\n",
    "            if cid in case_dict:\n",
    "                top_cases.append(case_dict[cid])\n",
    "            else:\n",
    "                logger.warning(f\"Case ID '{cid}' for query '{query_id}' not found in case base. Skipping this case for voting.\")\n",
    "\n",
    "        # Melakukan majority vote untuk memprediksi solusi\n",
    "        if not top_cases:\n",
    "            logger.warning(f\"No valid top-k cases found for query {query_id}. Skipping majority vote, setting predicted solution to 'N/A'.\")\n",
    "            predicted = \"N/A\"\n",
    "        else:\n",
    "            predicted = majority_vote(top_cases)\n",
    "        \n",
    "        # Menambahkan hasil prediksi untuk kueri ini ke daftar 'results'\n",
    "        results.append({\n",
    "            \"query_id\": query_id,\n",
    "            \"predicted_solution\": predicted,\n",
    "            # Pastikan hanya mengambil 5 ID teratas jika ada lebih, sesuai format output.\n",
    "            \"top_5_case_ids\": top_case_ids[:5]  \n",
    "        })\n",
    "        processed_queries += 1\n",
    "    \n",
    "    logger.info(f\"Processed {processed_queries} queries for prediction.\")\n",
    "\n",
    "    # Langkah 6: Simpan hasil prediksi ke file CSV.\n",
    "    try:\n",
    "        with open(OUTPUT_FILE, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            # Membuat objek writer CSV. quoting=csv.QUOTE_ALL memastikan semua bidang di-quote.\n",
    "            writer = csv.writer(f, quoting=csv.QUOTE_ALL)\n",
    "            \n",
    "            # Menulis baris header untuk CSV\n",
    "            writer.writerow([\"query_id\", \"predicted_solution\", \"top_5_case_ids\"])\n",
    "            \n",
    "            # Menulis setiap baris hasil ke CSV\n",
    "            for r in results:\n",
    "                # Menggabungkan daftar ID kasus teratas menjadi satu string yang dipisahkan koma\n",
    "                top_ids_str = \", \".join(map(str, r.get(\"top_5_case_ids\", [])))\n",
    "                writer.writerow([\n",
    "                    r.get(\"query_id\", \"\"), # Menggunakan .get() untuk menghindari KeyError jika bidang hilang\n",
    "                    r.get(\"predicted_solution\", \"\"),\n",
    "                    top_ids_str\n",
    "                ])\n",
    "\n",
    "        logger.info(f\"✅ Prediksi berhasil disimpan ke: '{OUTPUT_FILE}'\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ Gagal menulis prediksi ke '{OUTPUT_FILE}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa1582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Titik Masuk Skrip ---\n",
    "# Bagian ini memastikan bahwa fungsi main() dipanggil hanya ketika skrip dijalankan langsung.\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
