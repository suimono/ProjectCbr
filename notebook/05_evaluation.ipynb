{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd37edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional\n",
    "import logging\n",
    "import pandas as pd\n",
    "from collections import Counter # Digunakan lagi untuk extract_pasals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bebe9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Konfigurasi Awal ---\n",
    "# Mendefinisikan jalur file input dan output.\n",
    "QUERY_FILE = Path(\"data/eval/queries.json\")\n",
    "CASE_FILE = Path(\"data/processed/cases.json\") # Diperlukan untuk ground truth prediction\n",
    "RETRIEVED_CASES_FILE = Path(\"data/results/retrieved_cases.json\") # Hasil retrieval\n",
    "PREDICTIONS_FILE = Path(\"data/results/predictions.csv\") # Hasil prediksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c246f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "RETRIEVAL_METRICS_FILE = Path(\"data/eval/retrieval_metrics.csv\")\n",
    "PREDICTION_METRICS_FILE = Path(\"data/eval/prediction_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61e4270",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Mengatur logging untuk memberikan informasi, peringatan, dan kesalahan selama eksekusi.\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241cb43b",
   "metadata": {},
   "source": [
    "--- Fungsi Utilitas ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b71f9a7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def initialize_directories(file_path: Path) -> bool:\n",
    "    \"\"\"\n",
    "    Memastikan direktori (folder) tempat file output akan disimpan sudah ada.\n",
    "    Jika belum ada, fungsi ini akan membuatnya.\n",
    "    \n",
    "    Args:\n",
    "        file_path (Path): Objek Path dari file yang akan disimpan.\n",
    "                          Digunakan untuk mendapatkan direktori induknya.\n",
    "        \n",
    "    Returns:\n",
    "        bool: True jika direktori berhasil dipastikan/dibuat, False jika terjadi error.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        file_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        logger.info(f\"Output directory '{file_path.parent}' ensured.\")\n",
    "        return True\n",
    "    except OSError as e:\n",
    "        logger.error(f\"Error creating directory {file_path.parent}: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5e900b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_json_data(file_path: Path) -> Optional[List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Memuat data dari file JSON yang diberikan.\n",
    "    Fungsi ini juga melakukan validasi dasar untuk memastikan file ada, \n",
    "    formatnya adalah JSON, dan isinya berupa daftar.\n",
    "    \n",
    "    Args:\n",
    "        file_path (Path): Path ke file JSON yang akan dimuat.\n",
    "        \n",
    "    Returns:\n",
    "        Optional[List[Dict[str, Any]]]: Daftar kamus (data JSON) jika berhasil dimuat.\n",
    "                                         Mengembalikan None jika ada kesalahan (file tidak ditemukan,\n",
    "                                         format JSON salah, dll.).\n",
    "                                         Mengembalikan daftar kosong jika file ada tapi isinya kosong.\n",
    "    \"\"\"\n",
    "    if not file_path.exists():\n",
    "        logger.error(f\"File '{file_path}' not found.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "        if not isinstance(data, list):\n",
    "            logger.error(f\"Invalid data format in '{file_path}'. Expected a JSON array, got {type(data).__name__}.\")\n",
    "            return None\n",
    "            \n",
    "        if not data:\n",
    "            logger.warning(f\"No data found in '{file_path}'.\")\n",
    "            return []\n",
    "            \n",
    "        logger.info(f\"Successfully loaded {len(data)} entries from '{file_path}'.\")\n",
    "        return data\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        logger.error(f\"Failed to parse JSON from '{file_path}'. Invalid JSON format: {e}\")\n",
    "        return None\n",
    "    except UnicodeDecodeError as e:\n",
    "        logger.error(f\"Encoding error reading '{file_path}': {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error reading '{file_path}': {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901ec678",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def extract_pasals(text: Optional[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Mengekstrak semua referensi pasal dari sebuah string teks menggunakan ekspresi reguler.\n",
    "    Fungsi ini juga akan membersihkan dan menghilangkan duplikasi pasal yang ditemukan.\n",
    "    Contoh: \"Pasal 10, Pasal 10 Ayat (1) huruf a\" akan menjadi [\"Pasal 10\", \"Pasal 10 Ayat (1) Huruf A\"].\n",
    "    \n",
    "    Args:\n",
    "        text (Optional[str]): String teks yang mungkin berisi pasal-pasal.\n",
    "                              Bisa berupa None jika tidak ada teks.\n",
    "        \n",
    "    Returns:\n",
    "        List[str]: Daftar string pasal yang sudah diekstrak, dibersihkan, dan unik.\n",
    "    \"\"\"\n",
    "    pasal_pattern = re.compile(\n",
    "        r\"Pasal\\s+\\d+(?:\\s+Ayat\\s+\\(\\d+\\))?(?:\\s+huruf\\s+[a-zA-Z])?\",\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "    pasals = pasal_pattern.findall(text or \"\")\n",
    "    pasals = [p.title().strip() for p in pasals if p.strip()] \n",
    "    return list(dict.fromkeys(pasals))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b8791b",
   "metadata": {},
   "source": [
    "--- Fungsi Evaluasi ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f2819f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def eval_retrieval():\n",
    "    \"\"\"\n",
    "    Mengevaluasi kinerja retrieval menggunakan Mean Reciprocal Rank (MRR).\n",
    "    Asumsi:\n",
    "    - queries.json berisi 'query_id' dan 'case_id' (case_id adalah ground truth relevant case).\n",
    "    - retrieved_cases.json berisi 'query_id' dan 'top_k_case_ids' (hasil retrieval yang diurutkan).\n",
    "    \"\"\"\n",
    "    logger.info(\"Starting retrieval evaluation...\")\n",
    "\n",
    "    # Pastikan direktori output ada\n",
    "    if not initialize_directories(RETRIEVAL_METRICS_FILE):\n",
    "        return\n",
    "\n",
    "    queries = load_json_data(QUERY_FILE)\n",
    "    retrieved_data = load_json_data(RETRIEVED_CASES_FILE)\n",
    "\n",
    "    if queries is None or retrieved_data is None:\n",
    "        logger.error(\"Failed to load necessary data for retrieval evaluation. Exiting.\")\n",
    "        return\n",
    "    if not queries or not retrieved_data:\n",
    "        logger.warning(\"No data to evaluate for retrieval. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Buat kamus untuk akses cepat data retrieved berdasarkan query_id\n",
    "    retrieved_dict = {item.get(\"query_id\"): item.get(\"top_k_case_ids\", []) \n",
    "                      for item in retrieved_data if item.get(\"query_id\")}\n",
    "\n",
    "    reciprocal_ranks = []\n",
    "\n",
    "    for query_entry in queries:\n",
    "        query_id = query_entry.get(\"query_id\")\n",
    "        ground_truth_case_id = query_entry.get(\"case_id\") # Asumsi: case_id adalah ground truth\n",
    "\n",
    "        if not query_id or not ground_truth_case_id:\n",
    "            logger.warning(f\"Skipping query entry due to missing ID or ground truth: {query_entry}\")\n",
    "            continue\n",
    "\n",
    "        predicted_cases = retrieved_dict.get(query_id, [])\n",
    "        \n",
    "        # Hitung Reciprocal Rank (RR)\n",
    "        # MRR adalah rata-rata RR untuk setiap kueri. RR adalah 1/rank dari dokumen relevan pertama.\n",
    "        # Jika tidak ada dokumen relevan yang ditemukan, RR adalah 0.\n",
    "        rank = 0\n",
    "        for i, case_id in enumerate(predicted_cases):\n",
    "            if str(case_id) == str(ground_truth_case_id): # Konversi ke str untuk perbandingan yang konsisten\n",
    "                rank = i + 1\n",
    "                break\n",
    "        \n",
    "        if rank > 0:\n",
    "            reciprocal_ranks.append(1.0 / rank)\n",
    "        else:\n",
    "            reciprocal_ranks.append(0.0) # Tidak ada dokumen relevan yang ditemukan\n",
    "\n",
    "    # Hitung Mean Reciprocal Rank (MRR)\n",
    "    if reciprocal_ranks:\n",
    "        mrr = sum(reciprocal_ranks) / len(reciprocal_ranks)\n",
    "    else:\n",
    "        mrr = 0.0\n",
    "        logger.warning(\"No queries processed for MRR calculation.\")\n",
    "\n",
    "    # Simpan metrik retrieval\n",
    "    try:\n",
    "        df_metrics = pd.DataFrame([{\"MRR\": mrr}])\n",
    "        df_metrics.to_csv(RETRIEVAL_METRICS_FILE, index=False)\n",
    "        logger.info(f\"✅ Retrieval metrics (MRR: {mrr:.4f}) saved to '{RETRIEVAL_METRICS_FILE}'\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ Failed to save retrieval metrics: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5f37a1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def eval_prediction():\n",
    "    \"\"\"\n",
    "    Mengevaluasi kinerja prediksi solusi menggunakan metrik Precision, Recall, dan F1-score\n",
    "    (Micro-average) untuk masalah multi-label classification.\n",
    "    Asumsi:\n",
    "    - predictions.csv berisi 'query_id' dan 'predicted_solution'.\n",
    "    - queries.json berisi 'query_id' dan 'case_id'.\n",
    "    - cases.json berisi 'case_id' dan 'pasal' (ground truth solution).\n",
    "    \"\"\"\n",
    "    logger.info(\"Starting prediction evaluation...\")\n",
    "\n",
    "    # Pastikan direktori output ada\n",
    "    if not initialize_directories(PREDICTION_METRICS_FILE):\n",
    "        return\n",
    "\n",
    "    # Muat data\n",
    "    try:\n",
    "        predictions_df = pd.read_csv(PREDICTIONS_FILE)\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"Prediction file '{PREDICTIONS_FILE}' not found.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading prediction file '{PREDICTIONS_FILE}': {e}\")\n",
    "        return\n",
    "\n",
    "    queries = load_json_data(QUERY_FILE)\n",
    "    cases = load_json_data(CASE_FILE)\n",
    "\n",
    "    if queries is None or cases is None:\n",
    "        logger.error(\"Failed to load necessary data for prediction evaluation. Exiting.\")\n",
    "        return\n",
    "    if not queries or not cases:\n",
    "        logger.warning(\"No data to evaluate for prediction. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Buat kamus untuk akses cepat data kasus dan kueri\n",
    "    case_dict = {c.get(\"case_id\"): c.get(\"pasal\", \"\") \n",
    "                 for c in cases if c.get(\"case_id\")}\n",
    "    query_case_map = {q.get(\"query_id\"): q.get(\"case_id\") \n",
    "                      for q in queries if q.get(\"query_id\") and q.get(\"case_id\")}\n",
    "\n",
    "    total_tp = 0\n",
    "    total_fp = 0\n",
    "    total_fn = 0\n",
    "\n",
    "    for index, row in predictions_df.iterrows():\n",
    "        query_id = str(row.get(\"query_id\"))\n",
    "        predicted_solution_str = str(row.get(\"predicted_solution\", \"\"))\n",
    "\n",
    "        original_case_id = query_case_map.get(query_id)\n",
    "        if not original_case_id:\n",
    "            logger.warning(f\"Skipping prediction for query_id '{query_id}': Original case_id not found in queries data.\")\n",
    "            continue\n",
    "\n",
    "        ground_truth_pasal_str = case_dict.get(original_case_id)\n",
    "        if ground_truth_pasal_str is None:\n",
    "            logger.warning(f\"Skipping prediction for query_id '{query_id}': Ground truth pasal not found for case_id '{original_case_id}'.\")\n",
    "            continue\n",
    "\n",
    "        # Ekstrak pasal dari string ground truth dan prediksi\n",
    "        true_pasals = set(extract_pasals(ground_truth_pasal_str))\n",
    "        pred_pasals = set(extract_pasals(predicted_solution_str))\n",
    "\n",
    "        # Hitung True Positives (TP), False Positives (FP), False Negatives (FN) per kueri\n",
    "        tp = len(true_pasals.intersection(pred_pasals))\n",
    "        fp = len(pred_pasals - true_pasals)\n",
    "        fn = len(true_pasals - pred_pasals)\n",
    "\n",
    "        total_tp += tp\n",
    "        total_fp += fp\n",
    "        total_fn += fn\n",
    "    \n",
    "    # Hitung Micro-averaged Precision, Recall, F1-score\n",
    "    precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0.0\n",
    "    recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0.0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "    # Simpan metrik prediksi\n",
    "    try:\n",
    "        df_metrics = pd.DataFrame([{\"precision\": precision, \"recall\": recall, \"f1\": f1}])\n",
    "        df_metrics.to_csv(PREDICTION_METRICS_FILE, index=False)\n",
    "        logger.info(f\"✅ Prediction metrics (Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}) saved to '{PREDICTION_METRICS_FILE}'\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ Failed to save prediction metrics: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8335422c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Titik Masuk Skrip ---\n",
    "if __name__ == \"__main__\":\n",
    "    eval_retrieval()\n",
    "    eval_prediction()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
